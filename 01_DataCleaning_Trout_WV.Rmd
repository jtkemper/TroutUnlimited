---
title: "01_DataCleaning_Trout_WV"
author: "John Kemper"
date: "11/11/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(ggplot2)
library(ggthemes)
library(sf)
library(tools)
library(purrr)
library(tmap)
library(stringr)


```


###Load and save data
```{r}

# trout <- read_csv("C:/Users/jkemper/Downloads/tuwv.csv")

# dir.create("data")

# write.csv(trout, file = "data/trout_wv.csv")

trout <- read_csv("data/trout_wv.csv") 



```

##Clean data (remove extraneous columns and combine columns that have the same data)
```{r}

##Remove extraneous columns and arrange by sampling data for each site
##Also remove special characters
trout_cleaned <- trout %>%
  select(-c(Authority, SearchTime, GroupName, X1, Recorder,
            Comments)) %>%
  rename_all(~str_replace_all(., " ", "_")) %>%
  rename_all(~str_remove_all(., "[\\( \\)<>-]")) %>%
  select(-c(The_Location_Name))

names(trout_cleaned)


###Function to get the names of the user-specified variables
###Using the user-specified pattern
###E.g. specifying chr = "Turb" will return the names
###of all turbidity columns
name_extractor <- function(df, chr) {
  
  var_name <- df %>%
    names() %>%
    str_subset(., chr)
  
  if(length(var_name) > 1) {
    
    return(var_name)
  }
  
  else{return(NA)}
  
}


###Combines columns that share the pattern specified by the user in 
###the name_extractor
###E.g. if the user wishes to identify all the turbidity columns
###This function will combine them 
col_combiner <- function(df, lst) {
  
  combo_name <- paste0("Complete_", lst[1])
  
  col_comb <- df %>%
    mutate(., !!combo_name := coalesce(get(lst))) %>%
    select(., combo_name)
  

}

###Combine column names into lists that all refer to the same variable
###E.g. Turbidity_NTU, Turbidity_NTU_1, and Turbidity_NTU_2 would all be in the same list
combined_names <- map(all_cols, ~name_extractor(trout_clean_test, .)) %>%
  .[!is.na(.)]

combined_names
###Combine those redundant columns into one so we have a data frame of the 
###Complete observations for each variable
extracted_columns <- map_dfc(combined_names, ~col_combiner(trout_cleaned, .)) 

View(extracted_columns)

###Combine the complete variable observations with the sites and locations information
sites_and_locations <- select(trout_cleaned, 1:7)


trout_cleaned_complete <- cbind(sites_and_locations, extracted_columns)

unique(trout_cleaned_complete$AreaName)
```


###Do some data exploration - see how much data each site has and how much of each kind of data exist for all sites
```{r}

###Calculate how many observations are at each site
trout_observations <- trout_cleaned_complete %>%
  group_by(AreaName) %>%
  arrange(VisitDate, .by_group = TRUE) %>%
  summarise(n = n())


###Identify the sites with more than 5 observations
trout_observations_morethan5 <- trout_cleaned_complete %>%
  group_by(AreaName) %>%
  arrange(VisitDate, .by_group = TRUE) %>%
  summarise(n = n()) %>%
  filter(n > 5)

###Get data for the sites with more than five obervations 
trout_cleaned_selected_sites <- left_join(trout_cleaned_complete, trout_observations, by = "AreaName") %>%
  filter(n > 5)
  
###Function to count the number of observations in each column (excluding NAs)
counter <- function(df) {
  
  df %>%
    na.omit(.) %>%
    length()
    
}

###Count number of observations for each variable
observation_count <- map(trout_cleaned_selected_sites, ~counter(.)) %>%
  as.data.frame() %>%
  gather() %>%
  filter(value > 200)

###Select only variables that have more than 200 observations
trout_final <- trout_cleaned_selected_sites %>%
  select(observation_count$key[1:nrow(observation_count)])

names(trout_final)

###Calculate summary statistics
trout_sumstats <- trout_final %>%
  group_by(AreaName, Longitude, Latitude) %>%
  arrange(VisitDate, .by_group = TRUE) %>%
  summarise_at(., vars(5:20), list(~min(.), ~mean(.), ~max(.)), .keep_all= TRUE) %>%
  rename_all(~str_remove_all(., "Complete_"))
  


```


